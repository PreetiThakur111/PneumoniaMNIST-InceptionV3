{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision matplotlib numpy scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIx15gGIXZ4z",
        "outputId": "f10af924-664e-47a7-96cc-854ac1a579b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np                          # To handle arrays (images and labels)\n",
        "import matplotlib.pyplot as plt             # To show image plots\n",
        "import torch                                # Main PyTorch library\n",
        "import torch.nn as nn                       # For neural network layers\n",
        "from torchvision import models, transforms  # Pretrained models & image transformations\n",
        "from torch.utils.data import Dataset, DataLoader  # To create datasets and load in batches\n",
        "from PIL import Image                       # To handle images\n",
        "from sklearn.metrics import classification_report  # To print accuracy, precision, recall etc."
      ],
      "metadata": {
        "id": "aI4ixGfMXzjo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = np.load('train_images.npy')\n",
        "train_labels = np.load('train_labels.npy')\n",
        "\n",
        "print(\"Shape of train images:\", train_images.shape)\n",
        "print(\"Shape of train labels:\", train_labels.shape)\n",
        "\n",
        "# Let's show one image\n",
        "plt.imshow(train_images[0], cmap='gray')\n",
        "plt.title(f\"Label: {train_labels[0]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "WrvuQR9_Y8eD",
        "outputId": "9aa68ed1-2c01-427e-94fb-495c5d56eae9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train images: (3882, 28, 28)\n",
            "Shape of train labels: (3882, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# 🔁 Transformation for training images with more augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),                              # Convert NumPy array to PIL image\n",
        "    transforms.Resize((299, 299)),                        # Resize for InceptionV3\n",
        "    transforms.Grayscale(num_output_channels=3),          # Convert to 3-channel RGB\n",
        "    transforms.RandomHorizontalFlip(),                    # Flip horizontally\n",
        "    transforms.RandomRotation(15),                        # Random rotation within 15 degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2), # Slightly change brightness & contrast\n",
        "    transforms.ToTensor(),                                # Convert to PyTorch tensor\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)                 # Normalize channels to [-1, 1]\n",
        "])\n",
        "\n",
        "# ✅ Validation & Test transform — NO augmentation\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n"
      ],
      "metadata": {
        "id": "ylenU7F5ZTc2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "U0zRVmCmbM0T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 💻 Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 🔢 Ensure training labels are a flat array\n",
        "train_labels = np.array(train_labels).flatten()\n",
        "\n",
        "# ✅ Count number of samples per class\n",
        "class_counts = np.bincount(train_labels)  # [Normal, Pneumonia]\n",
        "print(\"Class distribution:\", class_counts)\n",
        "\n",
        "# 🧮 Inverse class frequency = higher weight for minority class\n",
        "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float32)\n",
        "class_weights = class_weights.to(device)\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "# ✅ Use class weights in loss function\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDlN3Yw1bUQb",
        "outputId": "1e68d891-aff9-4397-f7c1-b7809191c3fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution: [ 388 3494]\n",
            "Class weights: tensor([0.0026, 0.0003], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class PneumoniaDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx].astype(np.uint8)\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "SoQ8uJ_SbfAt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Load each .npy file individually\n",
        "train_images = np.load('train_images.npy')\n",
        "train_labels = np.load('train_labels.npy')\n",
        "\n",
        "val_images = np.load('val_images.npy')\n",
        "val_labels = np.load('val_labels.npy')\n",
        "\n",
        "test_images = np.load('test_images.npy')\n",
        "test_labels = np.load('test_labels.npy')\n"
      ],
      "metadata": {
        "id": "ExIlVj25bgcp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataset objects\n",
        "train_dataset = PneumoniaDataset(train_images, train_labels, transform=train_transform)\n",
        "val_dataset = PneumoniaDataset(val_images, val_labels, transform=test_transform)\n",
        "test_dataset = PneumoniaDataset(test_images, test_labels, transform=test_transform)\n"
      ],
      "metadata": {
        "id": "po7ZhYvzb9te"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "I4j8oakWcSUL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.inception_v3(pretrained=True)   # Load InceptionV3 with pre-trained weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuyP2TaxcVsC",
        "outputId": "adcd785c-fe54-4a23-8386-c5c79d4f777f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100%|██████████| 104M/104M [00:03<00:00, 31.5MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable auxiliary classifier (for simplicity)\n",
        "model.aux_logits = False\n",
        "\n",
        "# Replace the final fully-connected layer\n",
        "num_ftrs = model.fc.in_features        # Number of inputs to the last layer\n",
        "model.fc = nn.Linear(num_ftrs, 2)      # Change output to 2 classes"
      ],
      "metadata": {
        "id": "1_hn3b8mcY5v"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = model.to(device)  # Move model to device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY6VIS62cb3r",
        "outputId": "2f315abb-f543-474e-ae9f-7568a9acafb4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()                   # Good for multi-class classification\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer for faster learning"
      ],
      "metadata": {
        "id": "V-NENy1zceat"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=5):\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()               # Clear gradients from previous step\n",
        "            outputs = model(images)             # Forward pass: model makes predictions\n",
        "            loss = criterion(outputs, labels)   # Calculate how wrong the predictions are\n",
        "            loss.backward()                     # Backpropagation: calculate gradients\n",
        "            optimizer.step()                    # Update the model using gradients\n",
        "\n",
        "            # Track stats\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)    # Get class with highest score\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = 100 * correct / total\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f\"Training Loss: {avg_loss:.4f}, Accuracy: {acc:.2f}%\")"
      ],
      "metadata": {
        "id": "CNs-OGNucqWp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmrdeRlgcv5N",
        "outputId": "3dff3b51-caac-4dc2-b623-b5cb7a78b2e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-11-3547306552.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  label = int(self.labels[idx])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1618, Accuracy: 93.35%\n",
            "\n",
            "Epoch 2/5\n",
            "Training Loss: 0.1115, Accuracy: 95.70%\n",
            "\n",
            "Epoch 3/5\n",
            "Training Loss: 0.0981, Accuracy: 96.42%\n",
            "\n",
            "Epoch 4/5\n",
            "Training Loss: 0.0925, Accuracy: 96.70%\n",
            "\n",
            "Epoch 5/5\n",
            "Training Loss: 0.0950, Accuracy: 96.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():  # No need to calculate gradients during evaluation\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=[\"Normal\", \"Pneumonia\"]))"
      ],
      "metadata": {
        "id": "fapMdcBzePO-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "498RExEzeTY7",
        "outputId": "a411487c-8207-41be-a6d3-a27c9d0b0577"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-11-3547306552.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  label = int(self.labels[idx])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.92      0.71      0.80       234\n",
            "   Pneumonia       0.85      0.96      0.90       390\n",
            "\n",
            "    accuracy                           0.87       624\n",
            "   macro avg       0.88      0.84      0.85       624\n",
            "weighted avg       0.87      0.87      0.86       624\n",
            "\n"
          ]
        }
      ]
    }
  ]
}